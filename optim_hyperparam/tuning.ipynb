{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairie générales\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "path = os.getcwd()\n",
    "path_src = os.path.abspath(os.path.join(path, os.pardir,\"modelisation\"))\n",
    "sys.path.append(path_src)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"C:/Users/33623/Optimisation/Optimisation/modelisation/donnees/test/donnees.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['pf2','metal','larg',\t'esort_1',\t'esort_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuilPrepro(data):\n",
    "\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "    num_feat = [f for f in data.columns[1:] if data.dtypes[f]==np.float64]\n",
    "    cat_feat = [f for f in data.columns[1:] if data.dtypes[f]==object]\n",
    "\n",
    "    if len(cat_feat)>0:\n",
    "        num_prepro  = StandardScaler()\n",
    "        cat_prepro  = OneHotEncoder(handle_unknown='ignore')\n",
    "        prepro =  ColumnTransformer([('num',num_prepro,num_feat),('cat',cat_prepro, cat_feat)])\n",
    "    else:\n",
    "        num_prepro = StandardScaler()\n",
    "        prepro =  ColumnTransformer([('num',num_prepro,num_feat)])\n",
    "\n",
    "    return prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro = BuilPrepro(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline = Pipeline([(\"preprocessor\",Prepro),(\"model\", LGBMRegressor())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;larg&#x27;, &#x27;esort_1&#x27;,\n",
       "                                                   &#x27;esort_2&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;metal&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMRegressor(colsample_bytree=0.5, learning_rate=0.04))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;larg&#x27;, &#x27;esort_1&#x27;,\n",
       "                                                   &#x27;esort_2&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;metal&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMRegressor(colsample_bytree=0.5, learning_rate=0.04))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;larg&#x27;, &#x27;esort_1&#x27;, &#x27;esort_2&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;metal&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;larg&#x27;, &#x27;esort_1&#x27;, &#x27;esort_2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;metal&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bytree=0.5, learning_rate=0.04)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['larg', 'esort_1',\n",
       "                                                   'esort_2']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['metal'])])),\n",
       "                ('model',\n",
       "                 LGBMRegressor(colsample_bytree=0.5, learning_rate=0.04))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param = { \n",
    "    'model__colsample_bytree':0.5,\n",
    "    'model__learning_rate': 0.04,\n",
    "    'model__n_estimators':100\n",
    "}\n",
    "\n",
    "pipeline.set_params(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\scipy\\optimize\\_minimize.py:576: RuntimeWarning: Method L-BFGS-B cannot handle constraints.\n",
      "  warn('Method %s cannot handle constraints.' % method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.e-01 4.e-02 1.e+02]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[5.0000001e-01 4.0000000e-02 1.0000000e+02]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[5.000000e-01 4.000001e-02 1.000000e+02]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[5.e-01 4.e-02 1.e+02]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5    1.04 100.  ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.04       100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.04000001 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.04       100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03836301 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03836301 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03836302 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03836301 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03999644 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03999644 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03999645 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03999644 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03976985 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03976985 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03976986 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03976985 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03999638 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03999638 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03999639 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03999638 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03999631 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03999631 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03999632 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03999631 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03988308 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03988308 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03988309 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03988308 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5         1.0399963 100.       ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.0399963  100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03999631 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.0399963  100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998176 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03998176 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998177 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998176 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03992361 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03992361 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03992362 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03992361 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998175 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03998175 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998176 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998175 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998174 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03998174 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998175 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998174 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03995267 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03995267 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03995268 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03995267 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998173 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03998173 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998174 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998173 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998173 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03998173 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998174 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998173 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5         1.0399672 100.       ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.0399672  100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03996721 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.0399672  100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998173 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03998173 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998174 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998173 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03992457 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03992457 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03992458 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03992457 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998172 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03998172 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998173 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998172 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998171 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03998171 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998172 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998171 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03995314 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03995314 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03995315 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03995314 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998171 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03998171 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998172 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998171 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5         1.0399817 100.       ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.0399817  100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998171 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.0399817  100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03996742 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03996742 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03996743 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03996742 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5         1.0399817 100.       ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.0399817  100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998171 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.0399817  100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5         1.0399817 100.       ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.0399817  100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03998171 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.0399817  100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997456 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03997456 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997457 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997456 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997456 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03997456 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997457 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997456 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997456 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03997456 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997457 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997456 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997456 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03997456 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997457 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997456 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03989195 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03989195 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03989196 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03989195 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997455 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03997455 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997456 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997455 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997455 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03997455 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997456 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997455 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03993325 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03993325 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03993326 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03993325 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997454 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03997454 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997455 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997454 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997454 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.50000001   1.03997454 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997455 100.        ]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n",
      "[  0.5          1.03997454 100.00000001]\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n"
     ]
    }
   ],
   "source": [
    "param_list_init = [0.5,0.04,100]\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def tune_model(param_list):\n",
    "\n",
    "\n",
    "    print(param_list)\n",
    "    param_dict = { \n",
    "    'model__colsample_bytree':param_list[0],\n",
    "    'model__learning_rate': param_list[1],\n",
    "    'model__n_estimators':int(param_list[2])\n",
    "    }\n",
    "\n",
    "    pipeline.set_params(**param_dict)\n",
    "\n",
    "    X = data.drop(columns=['pf2'])\n",
    "    pipeline.fit(X,data['pf2'])\n",
    "\n",
    "    y_pred = pipeline.predict(X)\n",
    "    y_true = data['pf2']\n",
    "    return mean_squared_error(y_true,y_pred)\n",
    "\n",
    "def constraint_colsample_1(param_list):\n",
    "    return param_list[0] - 0.49\n",
    "\n",
    "def constraint_colsample_2(param_list):\n",
    "    return 0.71- param_list[0]\n",
    "\n",
    "def constraint_n_estimators_1(param_list):\n",
    "    return int(param_list[2]) - 50\n",
    "\n",
    "def constraint_n_estimators_2(param_list):\n",
    "    return 500 - int(param_list[2])\n",
    "\n",
    "def constraint_learning_rate_1(param_list):\n",
    "    return param_list[1] - 0.02\n",
    "\n",
    "def constraint_learning_rate_2(param_list):\n",
    "    return 0.12 - param_list[1]\n",
    "\n",
    "# Define constraints\n",
    "constraints = [{'type': 'ineq', 'fun': constraint_colsample_1},\n",
    "               {'type': 'ineq', 'fun': constraint_colsample_2},\n",
    "               {'type': 'ineq', 'fun': constraint_n_estimators_1},\n",
    "               {'type': 'ineq', 'fun': constraint_n_estimators_2},\n",
    "               {'type': 'ineq', 'fun': constraint_learning_rate_1},\n",
    "               {'type': 'ineq', 'fun': constraint_learning_rate_2}]\n",
    "\n",
    "\n",
    "result = minimize(tune_model, x0=param_list_init, method='L-BFGS-B', constraints=constraints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Parameters: [  0.5          1.03997454 100.        ]\n",
      "Best Accuracy: -0.21364885374642018\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal Parameters:\", result.x)\n",
    "print(\"Best Accuracy:\", -result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 133073, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 5.942981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35085073332083766"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_model(param_list_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessor',\n",
       "   ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                    ['larg', 'esort_1', 'esort_2']),\n",
       "                                   ('cat', OneHotEncoder(handle_unknown='ignore'),\n",
       "                                    ['metal'])])),\n",
       "  ('model', LGBMRegressor(colsample_bytree=0.5, learning_rate=0.04))],\n",
       " 'verbose': False,\n",
       " 'preprocessor': ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                  ['larg', 'esort_1', 'esort_2']),\n",
       "                                 ('cat', OneHotEncoder(handle_unknown='ignore'),\n",
       "                                  ['metal'])]),\n",
       " 'model': LGBMRegressor(colsample_bytree=0.5, learning_rate=0.04),\n",
       " 'preprocessor__n_jobs': None,\n",
       " 'preprocessor__remainder': 'drop',\n",
       " 'preprocessor__sparse_threshold': 0.3,\n",
       " 'preprocessor__transformer_weights': None,\n",
       " 'preprocessor__transformers': [('num',\n",
       "   StandardScaler(),\n",
       "   ['larg', 'esort_1', 'esort_2']),\n",
       "  ('cat', OneHotEncoder(handle_unknown='ignore'), ['metal'])],\n",
       " 'preprocessor__verbose': False,\n",
       " 'preprocessor__verbose_feature_names_out': True,\n",
       " 'preprocessor__num': StandardScaler(),\n",
       " 'preprocessor__cat': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'preprocessor__num__copy': True,\n",
       " 'preprocessor__num__with_mean': True,\n",
       " 'preprocessor__num__with_std': True,\n",
       " 'preprocessor__cat__categories': 'auto',\n",
       " 'preprocessor__cat__drop': None,\n",
       " 'preprocessor__cat__dtype': numpy.float64,\n",
       " 'preprocessor__cat__feature_name_combiner': 'concat',\n",
       " 'preprocessor__cat__handle_unknown': 'ignore',\n",
       " 'preprocessor__cat__max_categories': None,\n",
       " 'preprocessor__cat__min_frequency': None,\n",
       " 'preprocessor__cat__sparse': 'deprecated',\n",
       " 'preprocessor__cat__sparse_output': True,\n",
       " 'model__boosting_type': 'gbdt',\n",
       " 'model__class_weight': None,\n",
       " 'model__colsample_bytree': 0.5,\n",
       " 'model__importance_type': 'split',\n",
       " 'model__learning_rate': 0.04,\n",
       " 'model__max_depth': -1,\n",
       " 'model__min_child_samples': 20,\n",
       " 'model__min_child_weight': 0.001,\n",
       " 'model__min_split_gain': 0.0,\n",
       " 'model__n_estimators': 100,\n",
       " 'model__n_jobs': None,\n",
       " 'model__num_leaves': 31,\n",
       " 'model__objective': None,\n",
       " 'model__random_state': None,\n",
       " 'model__reg_alpha': 0.0,\n",
       " 'model__reg_lambda': 0.0,\n",
       " 'model__subsample': 1.0,\n",
       " 'model__subsample_for_bin': 200000,\n",
       " 'model__subsample_freq': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
